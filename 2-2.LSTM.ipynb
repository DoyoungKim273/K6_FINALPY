{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 생성</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_data = pd.read_excel('ship_data.xlsx')\n",
    "truck_data = pd.read_excel('truck_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_data['입항일시'] = pd.to_datetime(ship_data['입항일시'])\n",
    "ship_data['출항일시'] = pd.to_datetime(ship_data['출항일시'])\n",
    "truck_data['입문시각'] = pd.to_datetime(truck_data['입문시각'])\n",
    "truck_data['출문시각'] = pd.to_datetime(truck_data['출문시각'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_data = ship_data[['입항일시', '출항일시', '계선장소', 'number']]\n",
    "truck_data = truck_data[['입문시각', '출문시각','차종']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배의 입항시간과 출항시간 사이에 있는 화물차 데이터 병합 및 선박 개수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_with_ship_count(ship_data, truck_data):\n",
    "    # 병합된 데이터를 저장할 리스트 초기화\n",
    "    merged_data = []\n",
    "    # 배 데이터의 각 행을 반복 처리\n",
    "    for _, ship_row in ship_data.iterrows():\n",
    "        # 현재 배의 입항시간과 출항시간 사이에 있는 화물차 데이터를 필터링\n",
    "        relevant_trucks = truck_data[\n",
    "            # 화물차의 입문시각이 배의 입항시간 이후\n",
    "            (truck_data['입문시각'] >= ship_row['입항일시']) &\n",
    "            # 화물차의 출문시각이 배의 출항시간 이전\n",
    "            (truck_data['출문시각'] <= ship_row['출항일시']) \n",
    "        ]\n",
    "\n",
    "        # 해당 배의 기간 내에 있는 화물차 수를 계산\n",
    "        ship_count = relevant_trucks.shape[0]\n",
    "\n",
    "        # 필터링된 각 화물차 데이터에 대해 반복 처리\n",
    "        for _, truck_row in relevant_trucks.iterrows():\n",
    "            # 화물차 데이터를 필요한 형식으로 리스트에 추가\n",
    "            merged_data.append([\n",
    "                truck_row['입문시각'].year,\n",
    "                truck_row['입문시각'].month,\n",
    "                truck_row['입문시각'].day,\n",
    "                truck_row['입문시각'].hour,\n",
    "                truck_row['차종'],\n",
    "                ship_count,\n",
    "                (truck_row['출문시각'] - truck_row['입문시각']).total_seconds() / 60\n",
    "                # 입문시각과 출문시각 사이의 시간(분 단위)\n",
    "            ])\n",
    "\n",
    "        # 병합된 데이터를 데이터 프레임으로 변환하여 반환\n",
    "        # return 문의 위치 주의하기(안쪽에 있으면 truck만 반환함)\n",
    "        return pd.DataFrame(merged_data, columns=[\n",
    "                '입문시각_연도','입문시각_월', '입문시각_일', '입문시각_시간',\n",
    "                '차종', '선박_갯수', '걸린시간'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 병합 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   입문시각_연도  입문시각_월  입문시각_일  입문시각_시간           차종  선박_갯수  걸린시간\n",
      "0     2022       5      19       13  화물 소형(1t미만)    575   8.0\n",
      "1     2022       5      19       10  화물 대형(5t이상)    575  22.0\n",
      "2     2022       5      19        7  화물 소형(1t미만)    575  50.0\n",
      "3     2022       5      19       13  화물 대형(5t이상)    575  26.0\n",
      "4     2022       5      19       10  화물 대형(5t이상)    575   6.0\n",
      "5     2022       5      19       16  화물 대형(5t이상)    575  41.0\n",
      "6     2022       5      19        9  화물 소형(1t미만)    575  88.0\n",
      "7     2022       5      20        3  화물 대형(5t이상)    575  16.0\n",
      "8     2022       5      19        8  화물 대형(5t이상)    575  34.0\n",
      "9     2022       5      19       13  화물 대형(5t이상)    575  62.0\n"
     ]
    }
   ],
   "source": [
    "merged_data = merge_data_with_ship_count(ship_data, truck_data)\n",
    "print(merged_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['차종'] = merged_data['차종'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 데이터\n",
    "X = merged_data.drop(['걸린시간'], axis=1)\n",
    "# 타겟 데이터\n",
    "y = merged_data['걸린시간'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {}\n",
    "for column in X.select_dtypes(include=['object']).columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    X[column] = label_encoders[column].fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 및 데이터로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM 계층 정의\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 완전결의층 정의\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 초기 hidden state와 cell state를 0으로 초기화\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # LSTM 계층을 통과한 출력값과 상태값\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # 마지막 시점의 출력을 완전연결층에 통과시켜 최종 출력값을 계산\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 특성의 크기\n",
    "input_size = X_train.shape[1]\n",
    "# LSTM의 은닉상태 크기\n",
    "hidden_size = 50\n",
    "# LSTM 계층의 수\n",
    "num_layers = 2\n",
    "# 출력 크기 (예측하려는 타겟 변수의 수)\n",
    "output_size = 1\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수와 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss : 2845.2141\n",
      "Epoch [2/50], Loss : 6321.8716\n",
      "Epoch [3/50], Loss : 1729.1299\n",
      "Epoch [4/50], Loss : 2144.0950\n",
      "Epoch [5/50], Loss : 4753.6602\n",
      "Epoch [6/50], Loss : 4578.6733\n",
      "Epoch [7/50], Loss : 2201.7058\n",
      "Epoch [8/50], Loss : 2694.1968\n",
      "Epoch [9/50], Loss : 2980.1758\n",
      "Epoch [10/50], Loss : 2437.4084\n",
      "Epoch [11/50], Loss : 657.0085\n",
      "Epoch [12/50], Loss : 2355.1406\n",
      "Epoch [13/50], Loss : 2995.6299\n",
      "Epoch [14/50], Loss : 1460.4067\n",
      "Epoch [15/50], Loss : 2477.7522\n",
      "Epoch [16/50], Loss : 1113.1063\n",
      "Epoch [17/50], Loss : 2791.5186\n",
      "Epoch [18/50], Loss : 1852.4003\n",
      "Epoch [19/50], Loss : 1232.2968\n",
      "Epoch [20/50], Loss : 608.6743\n",
      "Epoch [21/50], Loss : 1164.9745\n",
      "Epoch [22/50], Loss : 2178.6843\n",
      "Epoch [23/50], Loss : 1654.8541\n",
      "Epoch [24/50], Loss : 1311.6403\n",
      "Epoch [25/50], Loss : 4524.7803\n",
      "Epoch [26/50], Loss : 2401.0046\n",
      "Epoch [27/50], Loss : 1678.2565\n",
      "Epoch [28/50], Loss : 2530.4778\n",
      "Epoch [29/50], Loss : 878.6728\n",
      "Epoch [30/50], Loss : 1864.7969\n",
      "Epoch [31/50], Loss : 833.1910\n",
      "Epoch [32/50], Loss : 2048.1233\n",
      "Epoch [33/50], Loss : 1011.9478\n",
      "Epoch [34/50], Loss : 1115.5272\n",
      "Epoch [35/50], Loss : 942.1181\n",
      "Epoch [36/50], Loss : 958.4890\n",
      "Epoch [37/50], Loss : 832.6028\n",
      "Epoch [38/50], Loss : 2270.9036\n",
      "Epoch [39/50], Loss : 1577.0962\n",
      "Epoch [40/50], Loss : 1387.7036\n",
      "Epoch [41/50], Loss : 1848.6603\n",
      "Epoch [42/50], Loss : 2141.0847\n",
      "Epoch [43/50], Loss : 608.5974\n",
      "Epoch [44/50], Loss : 1353.3829\n",
      "Epoch [45/50], Loss : 1364.7321\n",
      "Epoch [46/50], Loss : 1588.3246\n",
      "Epoch [47/50], Loss : 1365.6730\n",
      "Epoch [48/50], Loss : 1770.7679\n",
      "Epoch [49/50], Loss : 315.4023\n",
      "Epoch [50/50], Loss : 843.4985\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for features, targets in train_loader:\n",
    "        # LSTM 입력 형태로 변환(batch_size,seq_length, input_size)\n",
    "        features = features.unsqueeze(1)\n",
    "        # 타겟 텐서의 차원 추가\n",
    "        targets = targets.unsqueeze(1)\n",
    "        # 모델 예측\n",
    "        outputs = model(features)\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 역전파 수행\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss : {loss.item():.4f}')\n",
    "    # f는 포맷 문자열 리터럴 의미(f-string)\n",
    "    # 현재 에포크 번호와 총 에포크 수를 표시\n",
    "    # 손실 값을 소수점 네번째 자리까지 표시\n",
    "    # 각 에포크의 손실 값은 모델이 예측한 값과 실제 값 사이의 평균제곱 오차(MSE)를 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 1271.1031\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for features, targets in test_loader:\n",
    "        # LSTM 입력 형태로 변환(batch_size,seq_length, input_size)\n",
    "        features = features.unsqueeze(1)\n",
    "        # 타겟 텐서의 차원 추가\n",
    "        targets = targets.unsqueeze(1)\n",
    "        # 모델 예측\n",
    "        outputs = model(features)\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, targets)\n",
    "        # 테스트 손실 누적\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    # 평균 테스트 손실 계산\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Test Loss : {test_loss:.4f}')\n",
    "\n",
    "    # 1번째 시도 ) Test Loss : 1267.3691\n",
    "    # 2번째 시도 ) Test Loss : 1271.1031"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 성능(train score), 테스트 성능(test score), 평균 절대 오차(mean absolute error, MAE) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 25.6906, Train R2: -0.1150\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 예측\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    train_outputs = model(X_train_tensor.unsqueeze(1))\n",
    "    train_predictions = train_outputs.squeeze(1).numpy()\n",
    "    train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "    train_r2 = r2_score(y_train, train_predictions)\n",
    "    print(f\"Train MAE: {train_mae:.4f}, Train R2: {train_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 28.4074, Test R2: -0.1691\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor.unsqueeze(1))\n",
    "    test_predictions = test_outputs.squeeze(1).numpy()\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    print(f\"Test MAE: {test_mae:.4f}, Test R2: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 전체 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lstm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>예측 수행</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 불러오기\n",
    "model = torch.load('lstm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_processing_time 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_processing_time(model, year, month, day, hour, truck_type, ship_count):\n",
    "    # 입력 데이터를 데이터프레임으로 생성\n",
    "    input_data = pd.DataFrame([{\n",
    "        '입문시각_연도': year,\n",
    "        '입문시각_월': month,\n",
    "        '입문시각_일': day,\n",
    "        '입문시각_시간': hour,\n",
    "        '차종': truck_type,\n",
    "        '선박_갯수': ship_count\n",
    "    }])\n",
    "\n",
    "    # 문자열 컬럼을 레이블 인코딩(숫자로 변환)\n",
    "    for column in input_data.select_dtypes(include=['object']).columns:\n",
    "        # 사전에 정의된 레이블 인코더가 있는 경우\n",
    "        if column in label_encoders:\n",
    "            input_data[column] = label_encoders[column].transform(input_data[column])\n",
    "\n",
    "    # 데이터를 텐서로 변환\n",
    "    input_tensor = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "    # LSTM 입력 형태로 변환\n",
    "    input_tensor = input_tensor.unsqueeze(1)\n",
    "\n",
    "    # 모델을 평가 모드로 전환\n",
    "    model.eval()\n",
    "    # 그래디언트 계산 비활성화(메모리 절약)\n",
    "    with torch.no_grad():\n",
    "        # 모델 예측 수행\n",
    "        predicted_time = model(input_tensor)\n",
    "    \n",
    "    # 예측 결과를 숫자로 반환\n",
    "    return predicted_time.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차량 크기 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truck_size(truck_type):\n",
    "    if truck_type in [\"컨테이너차량\", \"특수차량(중장비)\", \"화물 대형(5t이상)\"]:\n",
    "        return \"대\"\n",
    "    elif truck_type in [\"화물 중형(1t이상~5t미만)\"]:\n",
    "        return \"중\"\n",
    "    elif  truck_type in [\"화물 소형(1t미만)\"]:\n",
    "        return \"소\"\n",
    "    else:\n",
    "        return \"알수없음\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시로 하나의 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예상 입출문 소요시간: 약 28.88765525817871 분, 차량 크기: 대\n"
     ]
    }
   ],
   "source": [
    "predicted_time = predict_processing_time(model, 2024, 7, 1, 1, '화물 대형(5t이상)', 1)\n",
    "\n",
    "print(f\"예상 입출문 소요시간: 약 {predicted_time} 분, 차량 크기: {truck_size('화물 대형(5t이상)')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
